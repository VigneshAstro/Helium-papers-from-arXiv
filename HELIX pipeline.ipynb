{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f23a04e",
   "metadata": {},
   "source": [
    "# HELIX - Helium Exoplanet Literature Investigation Xtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728c413",
   "metadata": {},
   "source": [
    "## Searching the arxiv for helium papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519b4d5",
   "metadata": {},
   "source": [
    "## First installing the arxiv package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb48b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing arxiv\n",
    "!pip install arxiv==1.3.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6db76",
   "metadata": {},
   "source": [
    "## Before running the code, search http://exoplanet.eu/catalog/all_fields/ and download the csv file and save it as exoplanets.csv. This gives the updated parameters for all exoplanets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e198c2",
   "metadata": {},
   "source": [
    "## This code below searches for arxiv and finds the papers that are related to helium. It also removes papers that are not related to helium (example brown dwarf or white dwarf planets)Run this code for finding the paper and store it in a file called step_1_helium_5.csv.\n",
    "## Do not forget to change the starting date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e7e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code reads the arxiv files from the start date and updates the list and stores it in helium_4.csv\n",
    "\n",
    "import arxiv\n",
    "import datetime\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Read exoplanet names from the CSV file\n",
    "exoplanet_names = set()\n",
    "with open('exoplanets.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        exoplanet_names.add(row['name'].strip())\n",
    "        alternate_names = row['alternate_names'].split(',')\n",
    "        for name in alternate_names:\n",
    "            exoplanet_names.add(name.strip())\n",
    "\n",
    "# Define the search query\n",
    "query = 'cat:astro-ph.EP AND (ti:\"helium\" OR ti:\"He\" OR abs:\"helium\" OR abs:\"He\" OR ti:\"1083\" OR ti:\"10833\" OR abs:\"1083\" OR abs:\"10833\")'\n",
    "start_date = datetime.date(2023, 7, 25) # searched until 2023 Nov 24\n",
    "\n",
    "# Search for papers\n",
    "search = arxiv.Search(\n",
    "    query=query,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "search_results = search.results()\n",
    "\n",
    "# Filter search results by publication date and keywords\n",
    "filtered_results = []\n",
    "for paper in search_results:\n",
    "    if paper.published.date() < start_date:\n",
    "        continue\n",
    "    if any(keyword in paper.title.lower() or keyword in paper.summary.lower() for keyword in [\"brown dwarf\", \"white dwarf\"]):\n",
    "        continue\n",
    "    filtered_results.append(paper)\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open('step_1_helium_5.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['arXiv ID', 'URL', 'Exoplanet Names Found'])\n",
    "\n",
    "    for paper in filtered_results:\n",
    "        arxiv_id = paper.entry_id.split('/')[-1]\n",
    "        url = f'https://arxiv.org/abs/{arxiv_id}'\n",
    "\n",
    "        # Find exoplanet names in the title and the abstract\n",
    "        exoplanet_names_title = {name for name in exoplanet_names if name in paper.title or name.replace(\" \", \"\") in paper.title}\n",
    "        exoplanet_names_abstract = {name for name in exoplanet_names if name in paper.summary or name.replace(\" \", \"\") in paper.summary}\n",
    "        exoplanet_names_found = exoplanet_names_title | exoplanet_names_abstract\n",
    "\n",
    "        # Write the result to the CSV file\n",
    "        writer.writerow([arxiv_id, url, ', '.join(exoplanet_names_found)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86b84b",
   "metadata": {},
   "source": [
    "## The code above also has many false positives that are not helium studies. Hence manually have to check them and shortlist the exact helium observation planets in the files step_2_helium_shortlisted.csv. If you change the name, please change the name in the code below as well.\n",
    "\n",
    "## The code below read the step_2_helium_shortlisted.csv file and arrange them in planets order (alphabetically) in the file step_3_helium_planets_update.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c5bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# read the data from the exoplanets file and store it in a dictionary\n",
    "exoplanet_data = {}\n",
    "with open('exoplanets.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    # get the header row\n",
    "    header = next(reader)\n",
    "    # iterate over the rows in the file\n",
    "    for row in reader:\n",
    "        # use the planet name as the key in the dictionary\n",
    "        planet_name = row[0]\n",
    "        # get the headers and data for the planet\n",
    "        planet_headers = header[2:]\n",
    "        planet_data = row[2:]\n",
    "        # store the data in a dictionary for the planet\n",
    "        exoplanet_data[planet_name] = (planet_headers, planet_data)\n",
    "\n",
    "# create a dictionary to store the planets and corresponding urls\n",
    "planet_urls = {}\n",
    "\n",
    "# read the data from the original file\n",
    "with open('step_2_helium_shortlisted.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    # skip the header row\n",
    "    next(reader)\n",
    "    # iterate over the rows in the file\n",
    "    for row in reader:\n",
    "        # split the planets by comma followed by a space\n",
    "        planets = [p.strip() for p in row[1].split(',')]\n",
    "        # iterate over the planets\n",
    "        for planet in planets:\n",
    "            # add the planet to the dictionary if it doesn't exist\n",
    "            if planet not in planet_urls:\n",
    "                planet_urls[planet] = []\n",
    "            # add the url to the list of urls for the planet\n",
    "            planet_urls[planet].append(row[0])\n",
    "\n",
    "# create a new file to write the data to\n",
    "with open('step_3_helium_planets_update.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # get the headers from exoplanets.csv and add empty columns for columns 3-8\n",
    "    planet_headers = ['Planets', 'URL', 'excess_abs', 'excess_abs_min', 'excess_abs_max', 'upp_lim', 'mass_loss', 'mass_loss_min', 'mass_loss_max','mass_loss_upp'] + exoplanet_data[next(iter(exoplanet_data.keys()))][0]\n",
    "    # write the header row\n",
    "    writer.writerow(planet_headers)\n",
    "    # iterate over the planets in alphabetical order\n",
    "    for planet in sorted(planet_urls.keys()):\n",
    "        # get the data for the planet from the exoplanet data dictionary\n",
    "        if planet in exoplanet_data:\n",
    "            # get the headers and data for the planet\n",
    "            planet_headers, planet_data = exoplanet_data[planet]\n",
    "            # create a list of the data for the planet in the correct order\n",
    "            planet_row = [planet, ', '.join(planet_urls[planet]), '', '', '', '', '', '', '', ''] + planet_data\n",
    "            # write the row for the planet\n",
    "            writer.writerow(planet_row)\n",
    "        else:\n",
    "            # write a row with the planet and url, leaving the exoplanet data columns empty\n",
    "            writer.writerow([planet, ', '.join(planet_urls[planet]), '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3881898",
   "metadata": {},
   "source": [
    "## After this add the excess abs, excess abs min and max limits or upper limits in the step_3_helium_planets_for_plots.csv file manually . This is a crucial step. And manually copy these to new row in helium_planets_for_plots.csv or if the planets already exist, manually change the specific columns.\n",
    "\n",
    "## We will use helium_planets_for_plots.csv to create a different csv file to use for calculations. And we will store the file as helium_planets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV file\n",
    "input_file = 'helium_planets_for_plots.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Select the first 10 columns\n",
    "selected_columns = df.iloc[:, :10]\n",
    "\n",
    "# Write the selected columns to a new CSV file\n",
    "output_file = 'helium_planets.csv'\n",
    "selected_columns.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
